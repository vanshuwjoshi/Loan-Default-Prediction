{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.pandas.set_option('display.max_columns',None) \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"441D1train.csv\") \n",
    "test = pd.read_csv(\"441D1test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the Id column\n",
    "train = train.drop('Id',axis=1) \n",
    "test = test.drop('Id',axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,0:8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train['Default'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting features using Boruta\n",
    "feat_selector = BorutaPy(rf1, n_estimators='auto', verbose=2, random_state=1)\n",
    "feat_selector.fit(X_train_val, Y_train_val)\n",
    "feat_selector.support_ \n",
    "# Hence we choose 5 columns (Age, Experience, Car_Ownership, CURRENT_JOB_YRS, CURRENT_HOUSE_YRS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train data \n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X_train, Y_train, test_size= 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only 5 columns (Age, Experience, Car_Ownership, CURRENT_JOB_YRS, CURRENT_HOUSE_YRS) \n",
    "train_1 = train_features[['Age','Experience','Car_Ownership','CURRENT_JOB_YRS','CURRENT_HOUSE_YRS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_features[['Age','Experience','Car_Ownership','CURRENT_JOB_YRS','CURRENT_HOUSE_YRS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling of data\n",
    "sc = StandardScaler()\n",
    "train_1 = sc.fit_transform(train_1)\n",
    "test_1 = sc.transform(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(random_state = 0)\n",
    "lr_clf.fit(train_1, train_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01 degrees.\n"
     ]
    }
   ],
   "source": [
    "predictions_lr = lr_clf.predict(test_1) \n",
    "error_lr = abs(predictions_lr-test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(error_lr), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9919\n",
      "Accuracy score: 0.9911\n",
      "Recall score: 0.9910633597750779\n",
      "Precision score: 0.9910633597750779\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set:',lr_clf.score(train_1,train_labels))\n",
    "print('Accuracy score:', accuracy_score(test_labels, predictions_lr)) \n",
    "print('Recall score:', recall_score(test_labels, predictions_lr))\n",
    "print('Precision score:',precision_score(test_labels, predictions_lr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_clf= GaussianNB()\n",
    "nb_clf.fit(train_1, train_labels)\n",
    "predictions_nb = nb_clf.predict(test_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.06 degrees.\n",
      "Accuracy on training set: 0.9388166666666666\n",
      "Accuracy score: 0.93925\n",
      "Recall score: 0.9450748067075008\n",
      "Precision score: 0.9337301587301587\n"
     ]
    }
   ],
   "source": [
    "error_nb = abs(predictions_nb-test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(error_nb), 2), 'degrees.')\n",
    "print('Accuracy on training set:',nb_clf.score(train_1,train_labels))\n",
    "print('Accuracy score:', accuracy_score(test_labels, predictions_nb)) \n",
    "print('Recall score:', recall_score(test_labels, predictions_nb))\n",
    "print('Precision score:',precision_score(test_labels, predictions_nb))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators = 1000, random_state = 0) \n",
    "rf_clf.fit(train_1, train_labels) \n",
    "predictions_rf = rf_clf.predict(test_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02 degrees.\n",
      "Accuracy on training set: 0.9991333333333333\n",
      "Accuracy score: 0.98425\n",
      "Recall score: 0.9844361883723265\n",
      "Precision score: 0.9839421918908069\n"
     ]
    }
   ],
   "source": [
    "error_rf = abs(predictions_rf-test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(error_rf), 2), 'degrees.')\n",
    "print('Accuracy on training set:',rf_clf.score(train_1,train_labels))\n",
    "print('Accuracy score:', accuracy_score(test_labels, predictions_rf)) \n",
    "print('Recall score:', recall_score(test_labels, predictions_rf))\n",
    "print('Precision score:',precision_score(test_labels, predictions_rf))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_clf = DecisionTreeClassifier()\n",
    "dec_clf.fit(train_1, train_labels)\n",
    "predictions_dec = dec_clf.predict(test_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.02 degrees.\n",
      "Accuracy on training set: 0.9991333333333333\n",
      "Accuracy score: 0.9791\n",
      "Recall score: 0.9791143689125414\n",
      "Precision score: 0.9789177793394237\n"
     ]
    }
   ],
   "source": [
    "error_dec = abs(predictions_dec-test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(error_dec), 2), 'degrees.')\n",
    "print('Accuracy on training set:',dec_clf.score(train_1,train_labels))\n",
    "print('Accuracy score:', accuracy_score(test_labels, predictions_dec)) \n",
    "print('Recall score:', recall_score(test_labels, predictions_dec))\n",
    "print('Precision score:',precision_score(test_labels, predictions_dec))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=0, solver='lbfgs',\n",
       "                                                 tol=0.0001, verbose=0,\n",
       "                                                 warm_start=False)),\n",
       "                             ('nb',\n",
       "                              GaussianNB(priors=None, var_smoothing=1e-09)),\n",
       "                             ('decision',\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort='deprecated',\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble of SVM and Logistic Regression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    " estimators=[('lr', lr_clf), ('nb', nb_clf), ('decision', dec_clf)],\n",
    " voting='hard')\n",
    "voting_clf.fit(train_1,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996\n",
      "0.98735\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set\",voting_clf.score(train_1, train_labels))\n",
    "print(\"Accuracy score\",voting_clf.score(test_1, test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=0, solver='lbfgs',\n",
       "                                                 tol=0.0001, verbose=0,\n",
       "                                                 warm_start=False)),\n",
       "                             ('decision',\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort='deprecated',\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble of Logistic rgression and Decision tree\n",
    "voting_clf2 = VotingClassifier(\n",
    " estimators=[('lr', lr_clf),('decision', dec_clf)],\n",
    " voting='hard')\n",
    "voting_clf2.fit(train_1, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01 degrees.\n",
      "Accuracy on training set: 0.99575\n",
      "Accuracy score: 0.9851\n",
      "Recall score: 0.9719851390701878\n",
      "Precision score: 0.9980410351582637\n"
     ]
    }
   ],
   "source": [
    "pred_clf2 = voting_clf2.predict(test_1)\n",
    "error_clf2 = abs(pred_clf2-test_labels)\n",
    "print('Mean Absolute Error:', round(np.mean(error_clf2), 2), 'degrees.')\n",
    "print('Accuracy on training set:',voting_clf2.score(train_1, train_labels))\n",
    "print('Accuracy score:', accuracy_score(test_labels, pred_clf2)) \n",
    "print('Recall score:', recall_score(test_labels, pred_clf2))\n",
    "print('Precision score:',precision_score(test_labels, pred_clf2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='binary:logistic',\n",
       "              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=True, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier() \n",
    "xgb_clf.fit(train_1,train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on train_data:  0.9985166666666667\n",
      "Accuracy score on test_data:  0.98955\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score on train_data: ', accuracy_score(y_true = train_labels, y_pred = xgb_clf.predict(train_1).round()))\n",
    "print('Accuracy score on test_data: ', accuracy_score(y_true = test_labels, y_pred = xgb_clf.predict(test_1).round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['Age','Experience','Car_Ownership','CURRENT_JOB_YRS','CURRENT_HOUSE_YRS']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sc.fit_transform(test)\n",
    "# Prediciton on test data using XGBoost \n",
    "test_predictions_xgb = xgb_clf.predict(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_xgb = pd.DataFrame(test_predictions_xgb) \n",
    "test_predictions_xgb.columns = [\"Default\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving prediction as csv file\n",
    "test_predictions_xgb.to_csv(\"C:/Users/vansh/OneDrive/Desktop/Data challenge 1/f2021-stat441-d1/final_xgb.csv\",header=True, index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Default\n",
       "0          1.0\n",
       "1          1.0\n",
       "2          1.0\n",
       "3          0.0\n",
       "4          1.0\n",
       "...        ...\n",
       "19995      0.0\n",
       "19996      0.0\n",
       "19997      0.0\n",
       "19998      0.0\n",
       "19999      0.0\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediciton on test data using Logistic regression\n",
    "test_predictions_lr = lr_clf.predict(test)\n",
    "test_predictions_lr = pd.DataFrame(test_predictions_lr)  \n",
    "test_predictions_lr.columns = [\"Default\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving prediction as csv file\n",
    "test_predictions_lr.to_csv(\"C:/Users/vansh/OneDrive/Desktop/Data challenge 1/f2021-stat441-d1/final_lr.csv\",header=True, index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_lr "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
